{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YapYOP_srblT"
   },
   "source": [
    "# LUS-CS433\n",
    "\n",
    "## 1. Code Exploration\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TZoIvD9nJuD1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoHSEUJqzlMR"
   },
   "source": [
    "### Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBJ5-wpVMirO"
   },
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "LshRvugQST4a",
    "outputId": "1c760e01-e530-4b22-eaa3-319ee1000f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# getting the list of names\\n!ls LUS\\\\ images/negative > neg_names.csv\\n!ls LUS\\\\ images/positive > pos_names.csv\\n\\nneg = pd.read_csv('neg_names.csv', header=None)\\npos = pd.read_csv('pos_names.csv', header=None)\\n\\ndata = neg.append(pos, ignore_index=True)\\ndata\\n\\npos = pd.read_csv('pos_names.csv', header=None)\\n\\n# removing .png extension\\npos[0] = pos[0].apply(lambda x: x[:-4])\\n\\n# extracting site\\npos[0] = pos[0].apply(lambda x: x.split('_')[2])\\n\\npos\\n\\nsums = pd.get_dummies(pos).sum()\\n\\nplt.bar(sums.index, sums.values)\\nplt.xlabel('Site')\\nplt.ylabel('Count')\\nplt.tight_layout()\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# getting the list of names\n",
    "!ls LUS\\ images/negative > neg_names.csv\n",
    "!ls LUS\\ images/positive > pos_names.csv\n",
    "\n",
    "neg = pd.read_csv('neg_names.csv', header=None)\n",
    "pos = pd.read_csv('pos_names.csv', header=None)\n",
    "\n",
    "data = neg.append(pos, ignore_index=True)\n",
    "data\n",
    "\n",
    "pos = pd.read_csv('pos_names.csv', header=None)\n",
    "\n",
    "# removing .png extension\n",
    "pos[0] = pos[0].apply(lambda x: x[:-4])\n",
    "\n",
    "# extracting site\n",
    "pos[0] = pos[0].apply(lambda x: x.split('_')[2])\n",
    "\n",
    "pos\n",
    "\n",
    "sums = pd.get_dummies(pos).sum()\n",
    "\n",
    "plt.bar(sums.index, sums.values)\n",
    "plt.xlabel('Site')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5jpXz_R_cP8"
   },
   "source": [
    "## 3. Creating Datasets\n",
    "\n",
    "### 3.1 Creating file folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "CAq_xxIcQAHU"
   },
   "outputs": [],
   "source": [
    "\"\"\"! mkdir data/LUS_proc_images\n",
    "! mkdir data/LUS_proc_images/train\n",
    "! mkdir data/LUS_proc_images/val\n",
    "! mkdir data/LUS_proc_images/train/true\n",
    "! mkdir data/LUS_proc_images/train/false\n",
    "! mkdir data/LUS_proc_images/val/true\n",
    "! mkdir data/LUS_proc_images/val/false \"\"\"\n",
    "\n",
    "! mkdir data/butter_proc_images\n",
    "! mkdir data/butter_proc_images/train\n",
    "! mkdir data/butter_proc_images/val\n",
    "! mkdir data/butter_proc_images/train/true\n",
    "! mkdir data/butter_proc_images/train/false\n",
    "! mkdir data/butter_proc_images/val/true\n",
    "! mkdir data/butter_proc_images/val/false "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main mask used to capture the relevant portion of LUS images. Crafted manually. Is [1,1,1] where image is relevant\n",
    "\n",
    "# Image dimensions\n",
    "nb_rows = 1080\n",
    "nb_cols = 792\n",
    "nb_channels = 3\n",
    "\n",
    "mask = np.zeros([nb_rows, nb_cols, nb_channels])\n",
    "\n",
    "# Filling mask\n",
    "for row in range(nb_rows):\n",
    "    for col in range(nb_cols):\n",
    "        # Delimitations of the cone like portion of a LUS image\n",
    "        if row > 25 and row < 1010 and col < 762 and (-4/5 * row + 293) < col and (4/5*row) + nb_cols-293 > col:\n",
    "            mask[row, col] = [1,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a function that will runs over our expert images, crops them, and organises them in a folder architecture that will later be used through the PyTorch DataLoader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "9HjtwX90Q985"
   },
   "outputs": [],
   "source": [
    "def create_samples(nb_samples, ratio, path):\n",
    "    \"\"\"\n",
    "    Crops nb_spamples images from the given folder and \n",
    "    organises them in training and validation folders, in \"true\" labeled subfolders\n",
    "    \"\"\"\n",
    "    images_path = glob.glob(path)\n",
    "    # TODO: do a random split mechanism ?\n",
    "    train = int(nb_samples * ratio)\n",
    "        \n",
    "    for i, image in enumerate(images_path[:nb_samples]):\n",
    "        cv2_img = cv2.imread(image)\n",
    "        masked_img = cv2.resize(cv2_img, (nb_cols, nb_rows))*mask792\n",
    "        # Selecting image name from path name\n",
    "        im_name = image.split(\"/\")[-1]\n",
    "        \n",
    "        if i >= train:\n",
    "            cv2.imwrite(f\"data/butter_proc_images/val/true/{im_name}\", masked_img)\n",
    "        else:\n",
    "            success = cv2.imwrite(f\"data/butter_proc_images/train/true/{im_name}\", masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "BwzO-NptULV2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Make sure that the files are empty\\n! rm -rfv data/LUS_proc_images/val/true/*\\n! rm -rfv data/LUS_proc_images/train/true/*'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure that the files are empty\n",
    "\"\"\"! rm -rfv data/LUS_proc_images/val/true/*\n",
    "! rm -rfv data/LUS_proc_images/train/true/*\"\"\"\n",
    "\n",
    "# Generates the samples!\n",
    "nb_samples = 3455\n",
    "ratio = 0.8\n",
    "path = \"data/Ultrason butterflynetwork/*.png\"\n",
    "create_samples(nb_samples, ratio, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e812724c6b70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimages_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m792\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#CHECK THAT INDEED ALL IMAGES HAVE THE SAME SHAPE\n",
    "path = \"data/LUS_proc_images/train/true/*.png\"\n",
    "images_path = glob.glob(path)\n",
    "for image in images_path:\n",
    "    x = cv2.imread(image)\n",
    "    if(x.shape != (1080,792,3)):\n",
    "        print(x.shape)\n",
    "        print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(img, mask):\n",
    "    len_x,len_y, _ = img.shape\n",
    "    mean = np.mean(img)*(1080*792/active_792)\n",
    "    var = 0\n",
    "    for x in range(len_x):\n",
    "        for y in range(len_y):\n",
    "            if(mask[x,y,0]==1):\n",
    "                var += (img[x,y,0] - mean)**2\n",
    "    \n",
    "    var /= active_792 \n",
    "    \n",
    "    return mean, np.sqrt(var)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/LUS_proc_images/train/true/2_QPIG_1.png\"\n",
    "img = cv2.imread(path)\n",
    "\n",
    "mean = cv2.mean(img)[0]*(1080*792/active_792)\n",
    "mean2 = np.mean(img)\n",
    "\n",
    "print(mean, mean2, mean2/mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Efoy13Awt0CN"
   },
   "source": [
    "#### Compute mean brightness over all sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzgnfG9xH3He"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_brightness_df(path):\n",
    "    df = pd.DataFrame(columns = ['mean', 'std'])\n",
    "    images_path = glob.glob(path)\n",
    "    for i,image in enumerate(images_path):\n",
    "        img = cv2.imread(image)\n",
    "        m, s = compute_mean_std(img,mask792)\n",
    "        df.loc[i] = [m, s]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yAuH35czwDWy"
   },
   "outputs": [],
   "source": [
    "df = create_brightness_df(\"data/LUS_proc_images/train/true/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mean_std.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "Rnj8CtNoazDm",
    "outputId": "945d51a8-288a-46f3-ffc6-c9e50ce54ee6"
   },
   "outputs": [],
   "source": [
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "ULNS-ByZhjNT",
    "outputId": "37e83c23-db5b-4a4c-8575-d2b4f79fc4ae"
   },
   "outputs": [],
   "source": [
    "df['mean'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "NIAX_6fJfAbY",
    "outputId": "fd423328-d758-46e3-edcb-ed1a280e02cd"
   },
   "outputs": [],
   "source": [
    "df['std'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['mean']<15) & (df['std']<32)].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "mov5lGwFvVLv",
    "outputId": "02d6fe9e-bbbf-475a-e1f7-0c475e5c745e"
   },
   "outputs": [],
   "source": [
    "df2 = df.astype(int)\n",
    "df2 = pd.crosstab(df2['mean'], df2['std'])\n",
    "sns.heatmap(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_UP, MEAN_DOWN = 7, 120  #mean_down, mean_up (based around the described df frame)\n",
    "LAST_WRITE_NB_FRAMES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO comment\n",
    "def split_video(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    i = 0\n",
    "    df_video = pd.DataFrame(columns = ['mean', 'std'])\n",
    "    while(video.isOpened()):\n",
    "        ret, image = video.read()\n",
    "        if ret == True:\n",
    "            video.set(cv2.CAP_PROP_POS_MSEC,(i*1000))\n",
    "            image = image * mask\n",
    "            m, s = compute_mean_std(image, mask)\n",
    "            df_video.loc[i] = [m[0,0], s[0,0]]\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    video.release()\n",
    "    return df_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates samples from a video\n",
    "def create_samples_from_video(video_path, folder_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    i = 0\n",
    "    last_write = 100 #variable to avoid writing 2 images that are almost the same \n",
    "    \n",
    "    while(video.isOpened()):\n",
    "        ret, image = video.read()\n",
    "        if ret == True:\n",
    "            #if we have access to an image, we check the mean, after applying the mask\n",
    "            image = image * mask792\n",
    "            m = np.mean(image) *(1080*792/ active_792)\n",
    "            \n",
    "            if (m > MEAN_UP or m < MEAN_DOWN) and (last_write > LAST_WRITE_NB_FRAMES) :\n",
    "                cv2.imwrite(f\"{folder_path}/{video_path[31:-4]}_{i}.png\", image)\n",
    "                i+=1\n",
    "                last_write = 0\n",
    "            \n",
    "            last_write += 1\n",
    "        else:\n",
    "            #need to get out the while loop if we can't read a file\n",
    "            break\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_videos_sample(path,nb_videos,ratio):\n",
    "    videos_path = glob.glob(path)\n",
    "    videos_in_train = int(nb_videos * ratio)\n",
    "    #Creates first video in the train folder\n",
    "    for video_path in videos_path[:videos_in_train]:\n",
    "        create_samples_from_video(video_path, \"data/LUS_proc_images/train/false\")\n",
    "    \n",
    "    #then in the val folder\n",
    "    for video_path in videos_path[videos_in_train:nb_videos]:\n",
    "        create_samples_from_video(video_path, \"data/LUS_proc_images/val/false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_videos_sample(\"data/Ultrason butterflynetwork/*.mp4\", 50, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Renaming to appropriate format\n",
    "def replace_dot_by_underscore(path):\n",
    "    path_list = glob.glob(path)\n",
    "    \n",
    "    for old_path in path_list:\n",
    "        new_path = old_path.replace(\".\", \"_\", 1)\n",
    "        os.rename(old_path, new_path)\n",
    "        \n",
    "replace_dot_by_underscore(\"data/Ultrason butterflynetwork/*\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = split_video(\"data/Ultrason butterflynetwork/1_1_QAID_1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = split_video(\"data/Ultrason butterflynetwork/1_9_QLD.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "7H_woI-D1QA6",
    "outputId": "d3eb6b44-ddc0-4182-e175-99f4b9ef27b9"
   },
   "outputs": [],
   "source": [
    "df_video2 = df_video.astype(int)\n",
    "df_video2 = pd.crosstab(df_video2['mean'], df_video2['std'])\n",
    "sns.heatmap(df_video2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "u1Q3Q2-Z4meD",
    "outputId": "25eea101-1722-436c-e51f-f3d0ff16c6b2"
   },
   "outputs": [],
   "source": [
    "df_video.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frrtEa5C7HoG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lus.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
